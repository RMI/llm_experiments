{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO - find more about codebox, why csvs are stored in this hidden file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with code interpreter api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an unofficial open source project to interact with code interpreter\n",
    "! pip3 install \"codeinterpreterapi[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OPENAI_API_KEY from user input\n",
    "from getpass import getpass\n",
    "OPENAI_API_KEY = getpass(\"Enter your API key: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ['VERBOSE'] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeinterpreterapi import CodeInterpreterSession, File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt that uses online data - yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with CodeInterpreterSession() as session:\n",
    "    response = await session.generate_response(\n",
    "        \"\"\" \n",
    "Plot the relative performace of tech giants (Apple, \n",
    "Google, Microsoft, Amazon) in 2023. Use a normalized plot \n",
    "so we can easily compare the percentage changes of each stock's \n",
    "price over the period.\"\"\"\n",
    "    )\n",
    "    print (\"AI: \", response.content)\n",
    "    for file in response.files:\n",
    "        file.show_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt that uses local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # context manager for auto start/stop of the session\n",
    "    async with CodeInterpreterSession() as session:\n",
    "        # define the user request\n",
    "        user_request = \"Analyze this dataset and plot something interesting about it.\"\n",
    "        files = [\n",
    "            File.from_path(\"./iris.csv\"),\n",
    "        ]\n",
    "\n",
    "        # generate the response\n",
    "        response = await session.generate_response(\n",
    "            user_request, files=files\n",
    "        )\n",
    "\n",
    "        # output to the user\n",
    "        print(\"AI: \", response.content)\n",
    "        for file in response.files:\n",
    "            file.show_image()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # context manager for auto start/stop of the session\n",
    "    async with CodeInterpreterSession() as session:\n",
    "        # define the user request\n",
    "        user_request = \"Can you analyze kazakhstan's data in this file and plot production and transport emissions columns that end with kgCO2e/boe or kgCH4/boe using interactive visualization. Set year as interactive toggle.\"\n",
    "        files = [\n",
    "            File.from_path(\"/Users/rwang/Library/CloudStorage/OneDrive-SharedLibraries-RMI/Climate Action Engine - Documents/OCI Phase 2/OCI_2023/basedata_updates/info_2023-08-24.csv\"),\n",
    "        ]\n",
    "\n",
    "        # generate the response\n",
    "        response = await session.generate_response(\n",
    "            user_request, files=files\n",
    "        )\n",
    "\n",
    "        # output to the user\n",
    "        print(\"AI: \", response.content)\n",
    "        for file in response.files:\n",
    "            file.show_image()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Learn how to continue the conversation like what we can do in chatgpt-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    session_id = None\n",
    "\n",
    "    session = CodeInterpreterSession()\n",
    "    session.start()\n",
    "\n",
    "    print(\"Session ID:\", session.session_id)\n",
    "    session_id = session.session_id\n",
    "\n",
    "    response = session.generate_response_sync(\"Plot the bitcoin chart of 2023 YTD\")\n",
    "    response.show()\n",
    "\n",
    "    del session\n",
    "\n",
    "    assert session_id is not None\n",
    "    session = CodeInterpreterSession.from_id(session_id)\n",
    "\n",
    "    response = session.generate_response_sync(\"Now for the last 5 years\")\n",
    "    response.show()\n",
    "\n",
    "    session.stop()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/rwang/Library/CloudStorage/OneDrive-SharedLibraries-RMI/Climate Action Engine - Documents/OCI Phase 2/OCI_2023/basedata_updates/info_2023-08-24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df[df['country'] == 'Kazakhstan'][\n",
    "    ['Field Name','Year',\n",
    " 'gwp','Upstream Methane Intensity (kgCH4/boe)',\n",
    " 'Midstream Methane Intensity (kgCH4/boe)',\n",
    " 'Transport Methane Intensity (kgCH4/boe)',\n",
    " 'Downstream Methane Intensity (kgCH4/boe)',\n",
    " 'Upstream Emissions Intensity (kgCO2eq/boe)',\n",
    " 'Midstream Emissions Intensity (kgCO2eq/boe)',\n",
    " 'Transport Emissions Intensity (kgCO2eq/boe)',\n",
    " 'Downstream Emissions Intensity (kgCO2eq/boe)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.to_csv('./info_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # context manager for auto start/stop of the session\n",
    "    async with CodeInterpreterSession() as session:\n",
    "        # define the user request\n",
    "        user_request = \"Analyze this dataset and plot something interesting about it. Use GWP as toggle and plot time series\"\n",
    "        files = [\n",
    "            File.from_path(\"./info_small.csv\"),\n",
    "        ]\n",
    "\n",
    "        # generate the response\n",
    "        response = await session.generate_response(\n",
    "            user_request, files=files\n",
    "        )\n",
    "\n",
    "        # output to the user\n",
    "        print(\"AI: \", response.content)\n",
    "        for file in response.files:\n",
    "            file.show_image()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting kernel...\n",
      "Waiting for kernel to start...\n",
      "Waiting for kernel to start...\n",
      "Waiting for kernel to start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rwang/Library/Python/3.9/lib/python/site-packages/traitlets/traitlets.py:2548: FutureWarning: Supporting extra quotes around strings is deprecated in traitlets 5.0. You can use '0.0.0.0' instead of \"'0.0.0.0'\" if you require traitlets >=5.\n",
      "  warn(\n",
      "[I 2023-08-25 10:31:15.081 KernelGatewayApp] Jupyter Kernel Gateway 2.5.2 is available at http://0.0.0.0:8888\n",
      "[I 230825 10:31:15 web:2271] 200 GET /api (127.0.0.1) 1.23ms\n",
      "[I 2023-08-25 10:31:16.704 KernelGatewayApp] Kernel started: 225b87d0-827e-4d58-bb03-359c27025614, name: python3\n",
      "[I 230825 10:31:16 web:2271] 201 POST /api/kernels (127.0.0.1) 812.32ms\n",
      "[W 2023-08-25 10:31:16.706 KernelGatewayApp] No session ID specified\n",
      "[I 230825 10:31:17 web:2271] 101 GET /api/kernels/225b87d0-827e-4d58-bb03-359c27025614/channels (127.0.0.1) 637.62ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRECATION WARNING: Use agenerate_response for async generation.\n",
      "This function will be converted to sync in the future.\n",
      "You can use generate_response_sync for now.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python` with `{'code': \"import pandas as pd\\n\\n# Load the data\\ninfo_small = pd.read_csv('info_small.csv')\\n\\n# Display the first few rows of the dataframe\\ninfo_small.head()\"}`\n",
      "responded: {content}\n",
      "\n",
      "\u001b[0mimport pandas as pd\n",
      "\n",
      "# Load the data\n",
      "info_small = pd.read_csv('info_small.csv')\n",
      "\n",
      "# Display the first few rows of the dataframe\n",
      "info_small.head()\n",
      "Running code:\n",
      " import pandas as pd\n",
      "\n",
      "# Load the data\n",
      "info_small = pd.read_csv('info_small.csv')\n",
      "\n",
      "# Display the first few rows of the dataframe\n",
      "info_small.head()\n",
      "Output:\n",
      " Unnamed: 0  Field Name  Year  gwp  Upstream Methane Intensity (kgCH4/boe)  \\\n",
      "0         204  Akshabulak  2015   20                                0.822987   \n",
      "1         205  Akshabulak  2015  100                                0.822987   \n",
      "2         206  Akshabulak  2016   20                                1.014905   \n",
      "3         207  Akshabulak  2016  100                                1.014905   \n",
      "4         208  Akshabulak  2017   20                                0.986529   \n",
      "\n",
      "   Midstream Methane Intensity (kgCH4/boe)  \\\n",
      "0                                 0.008554   \n",
      "1                                 0.008303   \n",
      "2                                 0.008441   \n",
      "3                                 0.008193   \n",
      "4                                 0.008428   \n",
      "\n",
      "   Transport Methane Intensity (kgCH4/boe)  \\\n",
      "0                                 0.002257   \n",
      "1                                 0.002257   \n",
      "2                                 0.002256   \n",
      "3                                 0.002256   \n",
      "4                                 0.002255   \n",
      "\n",
      "   Downstream Methane Intensity (kgCH4/boe)  \\\n",
      "0                                  0.019444   \n",
      "1                                  0.019369   \n",
      "2                                  0.019375   \n",
      "3                                  0.019300   \n",
      "4                                  0.019360   \n",
      "\n",
      "   Upstream Emissions Intensity (kgCO2eq/boe)  \\\n",
      "0                                   95.468690   \n",
      "1                                   47.524325   \n",
      "2                                  115.659452   \n",
      "3                                   57.220011   \n",
      "4                                  112.629583   \n",
      "\n",
      "   Midstream Emissions Intensity (kgCO2eq/boe)  \\\n",
      "0                                    31.993701   \n",
      "1                                    31.325098   \n",
      "2                                    31.783901   \n",
      "3                                    31.118946   \n",
      "4                                    31.717484   \n",
      "\n",
      "   Transport Emissions Intensity (kgCO2eq/boe)  \\\n",
      "0                                    14.593556   \n",
      "1                                    13.382811   \n",
      "2                                    14.584203   \n",
      "3                                    13.374401   \n",
      "4                                    14.574327   \n",
      "\n",
      "   Downstream Emissions Intensity (kgCO2eq/boe)  \n",
      "0                                    364.050603  \n",
      "1                                    363.038449  \n",
      "2                                    363.651609  \n",
      "3                                    362.642578  \n",
      "4                                    363.396586\n",
      "\n",
      "\u001b[36;1m\u001b[1;3m[...]\n",
      "\n",
      "1                                    13.382811   \n",
      "2                                    14.584203   \n",
      "3                                    13.374401   \n",
      "4                                    14.574327   \n",
      "\n",
      "   Downstream Emissions Intensity (kgCO2eq/boe)  \n",
      "0                                    364.050603  \n",
      "1                                    363.038449  \n",
      "2                                    363.651609  \n",
      "3                                    362.642578  \n",
      "4                                    363.396586\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThe dataset contains several columns. However, you mentioned that you're interested in creating a time series stacked bar chart for CH4 and CO2eq, and having dropdown toggles for Field Name and gwp. \n",
      "\n",
      "Unfortunately, I don't see these specific columns in the dataset. Could you please clarify which columns correspond to CH4, CO2eq, Field Name, and gwp? This will help me create the appropriate visualizations.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI:  The dataset contains several columns. However, you mentioned that you're interested in creating a time series stacked bar chart for CH4 and CO2eq, and having dropdown toggles for Field Name and gwp. \n",
      "\n",
      "Unfortunately, I don't see these specific columns in the dataset. Could you please clarify which columns correspond to CH4, CO2eq, Field Name, and gwp? This will help me create the appropriate visualizations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:31:42.819 KernelGatewayApp] Received signal to terminate.\n",
      "[I 2023-08-25 10:31:43.694 KernelGatewayApp] Kernel shutdown: 225b87d0-827e-4d58-bb03-359c27025614\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    # context manager for auto start/stop of the session\n",
    "    async with CodeInterpreterSession() as session:\n",
    "        # define the user request\n",
    "        user_request = \"Analyze this dataset and create an interactive dashboard composed of two time series stacked bar chart - one for CH4 and one for CO2eq. Have two dropdown toggles: one for Field Name, the other for gwp\"\n",
    "        files = [\n",
    "            File.from_path(\"./info_small.csv\"),\n",
    "        ]\n",
    "\n",
    "        # generate the response\n",
    "        response = await session.generate_response(\n",
    "            user_request, files=files\n",
    "        )\n",
    "\n",
    "        # output to the user\n",
    "        print(\"AI: \", response.content)\n",
    "        for file in response.files:\n",
    "            file.show_image()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It seems that the AI is having trouble interpreting the request. Let's try to normalize the table and see if AI gets smarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_melt = df_small.melt(id_vars=['Field Name','Year','gwp'], value_vars=['Upstream Methane Intensity (kgCH4/boe)','Midstream Methane Intensity (kgCH4/boe)','Transport Methane Intensity (kgCH4/boe)','Downstream Methane Intensity (kgCH4/boe)','Downstream Methane Intensity (kgCH4/boe)','Upstream Emissions Intensity (kgCO2eq/boe)','Midstream Emissions Intensity (kgCO2eq/boe)','Transport Emissions Intensity (kgCO2eq/boe)','Downstream Emissions Intensity (kgCO2eq/boe)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_melt['segment'] = df_small_melt['variable'].apply(lambda x: x.split(' ')[0])\n",
    "df_small_melt['metric']=df_small_melt['variable'].apply(lambda x: 'CH4' if 'Methane' in x else 'CO2eq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_melt.to_csv('info_small_melt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using a LocalBox which is not fully isolated\n",
      "      and not scalable across multiple users.\n",
      "      Make sure to use a CODEBOX_API_KEY in production.\n",
      "      Set envar SHOW_INFO=False to not see this again.\n",
      "\n",
      "Starting kernel...\n",
      "Waiting for kernel to start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rwang/Library/Python/3.9/lib/python/site-packages/traitlets/traitlets.py:2548: FutureWarning: Supporting extra quotes around strings is deprecated in traitlets 5.0. You can use '0.0.0.0' instead of \"'0.0.0.0'\" if you require traitlets >=5.\n",
      "  warn(\n",
      "[I 2023-08-25 10:40:13.004 KernelGatewayApp] Jupyter Kernel Gateway 2.5.2 is available at http://0.0.0.0:8888\n",
      "[I 230825 10:40:13 web:2271] 200 GET /api (127.0.0.1) 0.62ms\n",
      "[I 2023-08-25 10:40:13.967 KernelGatewayApp] Kernel started: e85cb8d8-739e-4aca-a719-fc7036e607c1, name: python3\n",
      "[I 230825 10:40:13 web:2271] 201 POST /api/kernels (127.0.0.1) 491.32ms\n",
      "[W 2023-08-25 10:40:13.970 KernelGatewayApp] No session ID specified\n",
      "[I 230825 10:40:14 web:2271] 101 GET /api/kernels/e85cb8d8-739e-4aca-a719-fc7036e607c1/channels (127.0.0.1) 625.42ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRECATION WARNING: Use agenerate_response for async generation.\n",
      "This function will be converted to sync in the future.\n",
      "You can use generate_response_sync for now.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python` with `{'code': \"import pandas as pd\\n\\n# Load the data\\ndata = pd.read_csv('info_small_melt.csv')\\n\\n# Display the first few rows of the data\\ndata.head()\"}`\n",
      "responded: {content}\n",
      "\n",
      "\u001b[0mimport pandas as pd\n",
      "\n",
      "# Load the data\n",
      "data = pd.read_csv('info_small_melt.csv')\n",
      "\n",
      "# Display the first few rows of the data\n",
      "data.head()\n",
      "Running code:\n",
      " import pandas as pd\n",
      "\n",
      "# Load the data\n",
      "data = pd.read_csv('info_small_melt.csv')\n",
      "\n",
      "# Display the first few rows of the data\n",
      "data.head()\n",
      "Output:\n",
      " Unnamed: 0  Field Name  Year  gwp                                variable  \\\n",
      "0           0  Akshabulak  2015   20  Upstream Methane Intensity (kgCH4/boe)   \n",
      "1           1  Akshabulak  2015  100  Upstream Methane Intensity (kgCH4/boe)   \n",
      "2           2  Akshabulak  2016   20  Upstream Methane Intensity (kgCH4/boe)   \n",
      "3           3  Akshabulak  2016  100  Upstream Methane Intensity (kgCH4/boe)   \n",
      "4           4  Akshabulak  2017   20  Upstream Methane Intensity (kgCH4/boe)   \n",
      "\n",
      "      value   segment metric  \n",
      "0  0.822987  Upstream    CH4  \n",
      "1  0.822987  Upstream    CH4  \n",
      "2  1.014905  Upstream    CH4  \n",
      "3  1.014905  Upstream    CH4  \n",
      "4  0.986529  Upstream    CH4\n",
      "\n",
      "\u001b[36;1m\u001b[1;3m[...]\n",
      "       1  Akshabulak  2015  100  Upstream Methane Intensity (kgCH4/boe)   \n",
      "2           2  Akshabulak  2016   20  Upstream Methane Intensity (kgCH4/boe)   \n",
      "3           3  Akshabulak  2016  100  Upstream Methane Intensity (kgCH4/boe)   \n",
      "4           4  Akshabulak  2017   20  Upstream Methane Intensity (kgCH4/boe)   \n",
      "\n",
      "      value   segment metric  \n",
      "0  0.822987  Upstream    CH4  \n",
      "1  0.822987  Upstream    CH4  \n",
      "2  1.014905  Upstream    CH4  \n",
      "3  1.014905  Upstream    CH4  \n",
      "4  0.986529  Upstream    CH4\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThe dataset contains the following columns:\n",
      "\n",
      "- An unnamed column which seems to be an index.\n",
      "- `Field Name`: The name of the field.\n",
      "- `Year`: The year of the data.\n",
      "- `gwp`: Global Warming Potential, a measure of how much heat a greenhouse gas traps in the atmosphere.\n",
      "- `variable`: The type of measurement, in this case, it's \"Upstream Methane Intensity (kgCH4/boe)\".\n",
      "- `value`: The value of the measurement.\n",
      "- `segment`: The segment of the industry, in this case, it's \"Upstream\".\n",
      "- `metric`: The metric of the measurement, in this case, it's \"CH4\".\n",
      "\n",
      "Next, let's create an interactive dashboard with two time series stacked bar charts - one for CH4 and one for CO2eq. We'll use the Plotly and Dash libraries for this. \n",
      "\n",
      "However, please note that the current dataset only contains data for the CH4 metric. We would need additional data for CO2eq to create a chart for it. \n",
      "\n",
      "Let's proceed with creating a dashboard for the CH4 metric. We'll create a dropdown for the 'Field Name' and 'gwp' columns. The user can select a field name and a gwp value, and the chart will update to display the data for the selected field and gwp. \n",
      "\n",
      "Please note that the code will create a local web server and display the dashboard in a web browser. The dashboard will not be visible in this text-based interface. You can run the code on your local machine to view the dashboard. \n",
      "\n",
      "Here is the code to create the dashboard: \n",
      "\n",
      "```python\n",
      "import dash\n",
      "import dash_core_components as dcc\n",
      "import dash_html_components as html\n",
      "from dash.dependencies import Input, Output\n",
      "import plotly.express as px\n",
      "\n",
      "# Create a Dash application\n",
      "app = dash.Dash(__name__)\n",
      "\n",
      "# Define the layout\n",
      "app.layout = html.Div([\n",
      "    dcc.Dropdown(\n",
      "        id='field-dropdown',\n",
      "        options=[{'label': i, 'value': i} for i in data['Field Name'].unique()],\n",
      "        value=data['Field Name'].unique()[0]\n",
      "    ),\n",
      "    dcc.Dropdown(\n",
      "        id='gwp-dropdown',\n",
      "        options=[{'label': i, 'value': i} for i in data['gwp'].unique()],\n",
      "        value=data['gwp'].unique()[0]\n",
      "    ),\n",
      "    dcc.Graph(id='time-series-chart')\n",
      "])\n",
      "\n",
      "# Define the callback\n",
      "@app.callback(\n",
      "    Output('time-series-chart', 'figure'),\n",
      "    [Input('field-dropdown', 'value'),\n",
      "     Input('gwp-dropdown', 'value')]\n",
      ")\n",
      "def update_graph(selected_field, selected_gwp):\n",
      "    filtered_data = data[(data['Field Name'] == selected_field) & (data['gwp'] == selected_gwp)]\n",
      "    fig = px.bar(filtered_data, x='Year', y='value', color='metric', barmode='stack')\n",
      "    return fig\n",
      "\n",
      "# Run the application\n",
      "if __name__ == '__main__':\n",
      "    app.run_server(debug=True)\n",
      "```\n",
      "\n",
      "You can run this code in a Python environment where Dash and Plotly are installed. When you run the code, it will start a local web server and print a URL to the console. You can open this URL in a web browser to view the dashboard. \n",
      "\n",
      "Please let me know if you need further assistance.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI:  The dataset contains the following columns:\n",
      "\n",
      "- An unnamed column which seems to be an index.\n",
      "- `Field Name`: The name of the field.\n",
      "- `Year`: The year of the data.\n",
      "- `gwp`: Global Warming Potential, a measure of how much heat a greenhouse gas traps in the atmosphere.\n",
      "- `variable`: The type of measurement, in this case, it's \"Upstream Methane Intensity (kgCH4/boe)\".\n",
      "- `value`: The value of the measurement.\n",
      "- `segment`: The segment of the industry, in this case, it's \"Upstream\".\n",
      "- `metric`: The metric of the measurement, in this case, it's \"CH4\".\n",
      "\n",
      "Next, let's create an interactive dashboard with two time series stacked bar charts - one for CH4 and one for CO2eq. We'll use the Plotly and Dash libraries for this. \n",
      "\n",
      "However, please note that the current dataset only contains data for the CH4 metric. We would need additional data for CO2eq to create a chart for it. \n",
      "\n",
      "Let's proceed with creating a dashboard for the CH4 metric. We'll create a dropdown for the 'Field Name' and 'gwp' columns. The user can select a field name and a gwp value, and the chart will update to display the data for the selected field and gwp. \n",
      "\n",
      "Please note that the code will create a local web server and display the dashboard in a web browser. The dashboard will not be visible in this text-based interface. You can run the code on your local machine to view the dashboard. \n",
      "\n",
      "Here is the code to create the dashboard: \n",
      "\n",
      "```python\n",
      "import dash\n",
      "import dash_core_components as dcc\n",
      "import dash_html_components as html\n",
      "from dash.dependencies import Input, Output\n",
      "import plotly.express as px\n",
      "\n",
      "# Create a Dash application\n",
      "app = dash.Dash(__name__)\n",
      "\n",
      "# Define the layout\n",
      "app.layout = html.Div([\n",
      "    dcc.Dropdown(\n",
      "        id='field-dropdown',\n",
      "        options=[{'label': i, 'value': i} for i in data['Field Name'].unique()],\n",
      "        value=data['Field Name'].unique()[0]\n",
      "    ),\n",
      "    dcc.Dropdown(\n",
      "        id='gwp-dropdown',\n",
      "        options=[{'label': i, 'value': i} for i in data['gwp'].unique()],\n",
      "        value=data['gwp'].unique()[0]\n",
      "    ),\n",
      "    dcc.Graph(id='time-series-chart')\n",
      "])\n",
      "\n",
      "# Define the callback\n",
      "@app.callback(\n",
      "    Output('time-series-chart', 'figure'),\n",
      "    [Input('field-dropdown', 'value'),\n",
      "     Input('gwp-dropdown', 'value')]\n",
      ")\n",
      "def update_graph(selected_field, selected_gwp):\n",
      "    filtered_data = data[(data['Field Name'] == selected_field) & (data['gwp'] == selected_gwp)]\n",
      "    fig = px.bar(filtered_data, x='Year', y='value', color='metric', barmode='stack')\n",
      "    return fig\n",
      "\n",
      "# Run the application\n",
      "if __name__ == '__main__':\n",
      "    app.run_server(debug=True)\n",
      "```\n",
      "\n",
      "You can run this code in a Python environment where Dash and Plotly are installed. When you run the code, it will start a local web server and print a URL to the console. You can open this URL in a web browser to view the dashboard. \n",
      "\n",
      "Please let me know if you need further assistance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:41:40.603 KernelGatewayApp] Received signal to terminate.\n",
      "[I 2023-08-25 10:41:40.956 KernelGatewayApp] Kernel shutdown: e85cb8d8-739e-4aca-a719-fc7036e607c1\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    # context manager for auto start/stop of the session\n",
    "    async with CodeInterpreterSession() as session:\n",
    "        # define the user request\n",
    "        user_request = \"Analyze this dataset and create an interactive dashboard composed of two time series stacked bar chart - one for CH4 and one for CO2eq. Have two dropdown toggles: one for Field Name, the other for gwp\"\n",
    "        files = [\n",
    "            File.from_path(\"./info_small_melt.csv\"),\n",
    "        ]\n",
    "\n",
    "        # generate the response\n",
    "        response = await session.generate_response(\n",
    "            user_request, files=files\n",
    "        )\n",
    "\n",
    "        # output to the user\n",
    "        print(\"AI: \", response.content)\n",
    "        for file in response.files:\n",
    "            file.show_image()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x151ce3910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a Dash application\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "info_small_melt = pd.read_csv('./info_small_melt.csv')\n",
    "# Define the layout\n",
    "app.layout = html.Div([\n",
    "    dcc.Dropdown(\n",
    "        id='field-name-dropdown',\n",
    "        options=[{'label': i, 'value': i} for i in info_small_melt['Field Name'].unique()],\n",
    "        value='Akshabulak'\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id='gwp-dropdown',\n",
    "        options=[{'label': i, 'value': i} for i in info_small_melt['gwp'].unique()],\n",
    "        value=100\n",
    "    ),\n",
    "    dcc.Graph(id='ch4-graph'),\n",
    "    dcc.Graph(id='co2eq-graph')\n",
    "])\n",
    "\n",
    "# Define the callbacks\n",
    "@app.callback(\n",
    "    [Output('ch4-graph', 'figure'),\n",
    "     Output('co2eq-graph', 'figure')],\n",
    "    [Input('field-name-dropdown', 'value'),\n",
    "     Input('gwp-dropdown', 'value')]\n",
    ")\n",
    "def update_graphs(field_name, gwp):\n",
    "    filtered_df = info_small_melt[(info_small_melt['Field Name'] == field_name) & (info_small_melt['gwp'] == gwp)]\n",
    "    \n",
    "    ch4_df = filtered_df[filtered_df['metric'] == 'CH4']\n",
    "    ch4_fig = px.bar(ch4_df, x='Year', y='value', color='segment', title='CH4')\n",
    "    \n",
    "    co2eq_df = filtered_df[filtered_df['metric'] == 'CO2eq']\n",
    "    co2eq_fig = px.bar(co2eq_df, x='Year', y='value', color='segment', title='CO2eq')\n",
    "    \n",
    "    return ch4_fig, co2eq_fig\n",
    "\n",
    "# Run the application\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion on this experiment: data need to be normalized for AI to comprehend. I was totally blown away by AI's capacity data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
